package main

import (
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"strconv"
	"strings"
	"time"

	"cscan/api/internal/config"
	"cscan/api/internal/handler"
	"cscan/api/internal/svc"
	"cscan/model"
	"cscan/scheduler"

	"github.com/google/uuid"
	"github.com/redis/go-redis/v9"
	"github.com/zeromicro/go-zero/core/conf"
	"github.com/zeromicro/go-zero/core/logx"
	"github.com/zeromicro/go-zero/rest"
)

var configFile = flag.String("f", "etc/cscan.yaml", "the config file")

func main() {
	flag.Parse()

	var c config.Config

	
	conf.MustLoad(*configFile, &c)

	logx.MustSetup(c.Log)
	logx.DisableStat()

	fmt.Println(`
   ______ _____  ______          _   _ 
  / ____/ ____|/ __ \ \        / / | \ | |
 | |   | (___ | |  | \ \  /\  / /|  \| |
 | |    \___ \| |  | |\ \/  \/ / | .  |
 | |________) | |__| | \  /\  /  | |\  |
  \_____|_____/ \____/   \/  \/   |_| \_| 
                                         `)
	fmt.Println("---------------------------------------------------------")
	logx.Infof("ðŸš€ Initializing CScan API Service...")
	logx.Infof("âš™ï¸  Config loaded from: %s", *configFile)
	fmt.Println("---------------------------------------------------------")
	// åˆ›å»ºæœåŠ¡ä¸Šä¸‹æ–‡
	svcCtx := svc.NewServiceContext(c)

	// åˆ›å»ºHTTPæœåŠ¡å™¨
	server := rest.MustNewServer(c.RestConf)
	defer server.Stop()

	handler.RegisterHandlers(server, svcCtx)

	// åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨æœåŠ¡
	rdb := redis.NewClient(&redis.Options{
		Addr:     c.Redis.Host,
		Password: c.Redis.Pass,
	})
	schedulerSvc := scheduler.NewSchedulerService(rdb, svcCtx.SyncMethods)
	go schedulerSvc.Start()

	// å¯åŠ¨å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ¶ˆæ¯è®¢é˜…
	go startCronExecuteSubscriber(svcCtx, schedulerSvc.GetScheduler())

	// å¯åŠ¨å­¤å„¿ä»»åŠ¡æ¢å¤åŽå°ä»»åŠ¡ï¼ˆæ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼‰
	go startOrphanedTaskRecovery(svcCtx)

	// logx.Infof("Starting API server at %s:%d...", c.Host, c.Port)
	fmt.Println("---------------------------------------------------------")
	logx.Infof("âœ… CScan API is running at: %s:%d", c.Host, c.Port)
	logx.Infof("gn  Environment: %s | LogLevel: %s", c.Mode, c.Log.Level)
	logx.Infof("ðŸ“¡ Ready to handle requests...")
	fmt.Println("---------------------------------------------------------")
	server.Start()
}

// CronExecuteMessage å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ¶ˆæ¯
type CronExecuteMessage struct {
	CronTaskId  string `json:"cronTaskId"`
	WorkspaceId string `json:"workspaceId"`
	MainTaskId  string `json:"mainTaskId"`
	TaskName    string `json:"taskName"`
	Target      string `json:"target"`
	Config      string `json:"config"`
}

// startCronExecuteSubscriber å¯åŠ¨å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ¶ˆæ¯è®¢é˜…
func startCronExecuteSubscriber(svcCtx *svc.ServiceContext, sched *scheduler.Scheduler) {
	ctx := context.Background()
	pubsub := svcCtx.RedisClient.Subscribe(ctx, "cscan:cron:execute")
	defer pubsub.Close()

	logx.Info("Cron execute subscriber started")

	ch := pubsub.Channel()
	for msg := range ch {
		var execMsg CronExecuteMessage
		if err := json.Unmarshal([]byte(msg.Payload), &execMsg); err != nil {
			logx.Errorf("Failed to parse cron execute message: %v", err)
			continue
		}

		logx.Infof("Received cron execute message: cronTaskId=%s, taskName=%s", execMsg.CronTaskId, execMsg.TaskName)

		// åˆ›å»ºæ–°çš„ MainTask å¹¶æŽ¨é€åˆ°é˜Ÿåˆ—
		if err := createAndPushCronTask(ctx, svcCtx, sched, &execMsg); err != nil {
			logx.Errorf("Failed to create cron task: %v", err)
		}
	}
}

// createAndPushCronTask åˆ›å»ºå®šæ—¶ä»»åŠ¡çš„ MainTask å¹¶æŽ¨é€åˆ°é˜Ÿåˆ—
func createAndPushCronTask(ctx context.Context, svcCtx *svc.ServiceContext, sched *scheduler.Scheduler, msg *CronExecuteMessage) error {
	workspaceId := msg.WorkspaceId
	if workspaceId == "" {
		workspaceId = "default"
	}

	// è§£æžä»»åŠ¡é…ç½®
	var taskConfig map[string]interface{}
	if err := json.Unmarshal([]byte(msg.Config), &taskConfig); err != nil {
		return fmt.Errorf("failed to parse task config: %v", err)
	}

	// ç”Ÿæˆæ–°çš„ä»»åŠ¡ID
	newTaskId := uuid.New().String()

	// åˆ›å»ºæ–°çš„ MainTask
	taskModel := svcCtx.GetMainTaskModel(workspaceId)
	newTask := &model.MainTask{
		TaskId:      newTaskId,
		Name:        fmt.Sprintf("%s (å®šæ—¶)", msg.TaskName),
		Target:      msg.Target,
		Config:      msg.Config,
		Status:      model.TaskStatusCreated,
		IsCron:      true,
		CronRule:    msg.CronTaskId,
	}

	if err := taskModel.Insert(ctx, newTask); err != nil {
		return fmt.Errorf("failed to insert main task: %v", err)
	}

	logx.Infof("Created cron main task: taskId=%s, name=%s", newTaskId, newTask.Name)

	// è®¡ç®—å­ä»»åŠ¡æ•°é‡ï¼ˆåŸºäºŽç›®æ ‡æ•°é‡å’Œå¯ç”¨çš„æ¨¡å—æ•°ï¼‰
	targets := strings.Split(msg.Target, "\n")
	var validTargets []string
	for _, t := range targets {
		t = strings.TrimSpace(t)
		if t != "" {
			validTargets = append(validTargets, t)
		}
	}

	// è®¡ç®—å¯ç”¨çš„æ¨¡å—æ•°
	enabledModules := 0
	if ps, ok := taskConfig["portscan"].(map[string]interface{}); ok {
		if enable, _ := ps["enable"].(bool); enable {
			enabledModules++
		}
	}
	if ds, ok := taskConfig["domainscan"].(map[string]interface{}); ok {
		if enable, _ := ds["enable"].(bool); enable {
			enabledModules++
		}
	}
	if fp, ok := taskConfig["fingerprint"].(map[string]interface{}); ok {
		if enable, _ := fp["enable"].(bool); enable {
			enabledModules++
		}
	}
	if poc, ok := taskConfig["pocscan"].(map[string]interface{}); ok {
		if enable, _ := poc["enable"].(bool); enable {
			enabledModules++
		}
	}
	if dir, ok := taskConfig["dirscan"].(map[string]interface{}); ok {
		if enable, _ := dir["enable"].(bool); enable {
			enabledModules++
		}
	}
	if enabledModules == 0 {
		enabledModules = 1
	}

	// åˆ†æ‰¹å¤„ç†ç›®æ ‡
	batchSize := 50
	if bs, ok := taskConfig["batchSize"].(float64); ok && bs > 0 {
		batchSize = int(bs)
	}

	var batches []string
	for i := 0; i < len(validTargets); i += batchSize {
		end := i + batchSize
		if end > len(validTargets) {
			end = len(validTargets)
		}
		batches = append(batches, strings.Join(validTargets[i:end], "\n"))
	}
	if len(batches) == 0 {
		batches = []string{msg.Target}
	}

	subTaskCount := len(batches) * enabledModules

	// æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º STARTED
	now := time.Now()
	taskModel.Update(ctx, newTask.Id.Hex(), map[string]interface{}{
		"status":         model.TaskStatusStarted,
		"sub_task_count": subTaskCount,
		"sub_task_done":  0,
		"start_time":     now,
	})

	// ä¿å­˜ä¸»ä»»åŠ¡ä¿¡æ¯åˆ° Redis
	taskInfoKey := "cscan:task:info:" + newTaskId
	taskInfoData, _ := json.Marshal(map[string]interface{}{
		"workspaceId":    workspaceId,
		"mainTaskId":     newTask.Id.Hex(),
		"subTaskCount":   subTaskCount,
		"batchCount":     len(batches),
		"enabledModules": enabledModules,
	})
	svcCtx.RedisClient.Set(ctx, taskInfoKey, taskInfoData, 24*time.Hour)

	// ä»Žé…ç½®ä¸­èŽ·å–æŒ‡å®šçš„ Worker åˆ—è¡¨
	var workers []string
	if w, ok := taskConfig["workers"].([]interface{}); ok {
		for _, v := range w {
			if s, ok := v.(string); ok {
				workers = append(workers, s)
			}
		}
	}

	// ä¸ºæ¯ä¸ªæ‰¹æ¬¡åˆ›å»ºå­ä»»åŠ¡å¹¶æŽ¨é€åˆ°é˜Ÿåˆ—
	for i, batch := range batches {
		// å¤åˆ¶é…ç½®å¹¶æ›¿æ¢ç›®æ ‡
		subConfig := make(map[string]interface{})
		for k, v := range taskConfig {
			subConfig[k] = v
		}
		subConfig["target"] = batch
		subConfig["subTaskIndex"] = i
		subConfig["subTaskTotal"] = len(batches)
		subConfigBytes, _ := json.Marshal(subConfig)

		// ç”Ÿæˆå­ä»»åŠ¡ID
		subTaskId := newTaskId
		if len(batches) > 1 {
			subTaskId = newTaskId + "-" + strconv.Itoa(i)
		}

		schedTask := &scheduler.TaskInfo{
			TaskId:      subTaskId,
			MainTaskId:  newTask.Id.Hex(),
			WorkspaceId: workspaceId,
			TaskName:    newTask.Name,
			Config:      string(subConfigBytes),
			Priority:    0,
			Workers:     workers,
		}

		logx.Infof("Pushing cron sub-task %d/%d: taskId=%s, targets=%d", i+1, len(batches), subTaskId, len(strings.Split(batch, "\n")))

		if err := sched.PushTask(ctx, schedTask); err != nil {
			logx.Errorf("Failed to push cron task to queue: %v", err)
			continue
		}

		// ä¿å­˜å­ä»»åŠ¡ä¿¡æ¯åˆ° Redisï¼ˆå¤šæ‰¹æ¬¡æ—¶ï¼‰
		if len(batches) > 1 {
			subTaskInfoKey := "cscan:task:info:" + subTaskId
			subTaskInfoData, _ := json.Marshal(map[string]interface{}{
				"workspaceId":  workspaceId,
				"mainTaskId":   newTask.Id.Hex(),
				"subTaskCount": subTaskCount,
			})
			svcCtx.RedisClient.Set(ctx, subTaskInfoKey, subTaskInfoData, 24*time.Hour)
		}
	}

	logx.Infof("Cron task created and pushed: taskId=%s, batches=%d, subTaskCount=%d", newTaskId, len(batches), subTaskCount)
	return nil
}


// startOrphanedTaskRecovery å¯åŠ¨å­¤å„¿ä»»åŠ¡æ¢å¤åŽå°ä»»åŠ¡
// å®šæœŸæ£€æŸ¥å¹¶æ¢å¤å¡ä½çš„ä»»åŠ¡ï¼ˆçŠ¶æ€ä¸º STARTED ä½†é•¿æ—¶é—´æ²¡æœ‰æ›´æ–°çš„ä»»åŠ¡ï¼‰
func startOrphanedTaskRecovery(svcCtx *svc.ServiceContext) {
	logx.Info("Orphaned task recovery background job started")

	// æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for range ticker.C {
		recoverOrphanedTasks(svcCtx)
	}
}

// recoverOrphanedTasks æ¢å¤å­¤å„¿ä»»åŠ¡
func recoverOrphanedTasks(svcCtx *svc.ServiceContext) {
	ctx := context.Background()

	// èŽ·å–æ‰€æœ‰ workspace
	workspaces, err := svcCtx.WorkspaceModel.FindAll(ctx)
	if err != nil {
		logx.Errorf("[OrphanedTaskRecovery] Failed to get workspaces: %v", err)
		return
	}

	// ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼š30 åˆ†é’Ÿæ²¡æœ‰æ›´æ–°çš„ä»»åŠ¡è®¤ä¸ºéœ€è¦æ¢å¤
	cutoffTime := time.Now().Add(-30 * time.Minute)
	totalRecovered := 0

	for _, ws := range workspaces {
		taskModel := svcCtx.GetMainTaskModel(ws.Name)

		// æŸ¥æ‰¾çŠ¶æ€ä¸º STARTED ä¸”è¶…æ—¶çš„ä»»åŠ¡
		filter := map[string]interface{}{
			"status": "STARTED",
			"update_time": map[string]interface{}{
				"$lt": cutoffTime,
			},
		}

		tasks, err := taskModel.Find(ctx, filter, 0, 50)
		if err != nil {
			logx.Errorf("[OrphanedTaskRecovery] Failed to find tasks for workspace %s: %v", ws.Name, err)
			continue
		}

		for _, task := range tasks {
			// å°†ä»»åŠ¡çŠ¶æ€é‡ç½®ä¸º PENDING
			update := map[string]interface{}{
				"status":      "PENDING",
				"update_time": time.Now(),
			}

			if err := taskModel.UpdateByTaskId(ctx, task.TaskId, update); err != nil {
				logx.Errorf("[OrphanedTaskRecovery] Failed to update task %s: %v", task.TaskId, err)
				continue
			}

			// é‡æ–°å°†ä»»åŠ¡æŽ¨å…¥é˜Ÿåˆ—
			taskInfo := map[string]interface{}{
				"taskId":      task.TaskId,
				"mainTaskId":  task.TaskId,
				"workspaceId": ws.Name,
				"taskName":    task.Name,
				"config":      task.Config,
				"priority":    5, // æ¢å¤ä»»åŠ¡ä½¿ç”¨è¾ƒé«˜ä¼˜å…ˆçº§
				"createTime":  time.Now().Format("2006-01-02 15:04:05"),
			}

			taskData, _ := json.Marshal(taskInfo)
			score := float64(time.Now().Unix()) - 5000 // æé«˜ä¼˜å…ˆçº§

			publicQueueKey := "cscan:task:queue"
			if err := svcCtx.RedisClient.ZAdd(ctx, publicQueueKey, redis.Z{
				Score:  score,
				Member: taskData,
			}).Err(); err != nil {
				logx.Errorf("[OrphanedTaskRecovery] Failed to requeue task %s: %v", task.TaskId, err)
				continue
			}

			totalRecovered++
			logx.Infof("[OrphanedTaskRecovery] Recovered task %s for workspace %s", task.TaskId, ws.Name)
		}
	}

	// æ¸…ç†è¿‡æœŸçš„ processing é›†åˆè®°å½•
	cleanupStaleProcessingTasks(svcCtx)

	if totalRecovered > 0 {
		logx.Infof("[OrphanedTaskRecovery] Total recovered tasks: %d", totalRecovered)
	}
}

// cleanupStaleProcessingTasks æ¸…ç†è¿‡æœŸçš„å¤„ç†ä¸­ä»»åŠ¡è®°å½•
func cleanupStaleProcessingTasks(svcCtx *svc.ServiceContext) {
	ctx := context.Background()
	processingKey := "cscan:task:processing"

	taskIds, err := svcCtx.RedisClient.SMembers(ctx, processingKey).Result()
	if err != nil {
		return
	}

	cleaned := 0
	for _, taskId := range taskIds {
		statusKey := "cscan:task:status:" + taskId
		_, err := svcCtx.RedisClient.Get(ctx, statusKey).Result()
		if err != nil {
			// çŠ¶æ€ä¸å­˜åœ¨ï¼Œç›´æŽ¥æ¸…ç†
			svcCtx.RedisClient.SRem(ctx, processingKey, taskId)
			cleaned++
		}
	}

	if cleaned > 0 {
		logx.Infof("[OrphanedTaskRecovery] Cleaned up %d stale processing records", cleaned)
	}
}
